{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data collection\n",
    "import requests\n",
    "import json\n",
    "from math import ceil\n",
    "from time import sleep, time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "#data cleaning and \n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import networkx as nx"
   ]
  },
  {
   "source": [
    "## Collecting the data; our own TwitterAPI Class\n",
    "\n",
    "Create TwitterAPI class. Loop through list of bearer tokens, when rate limit of a single bearer token's API is reached.  \n",
    "Takes list of bearer tokens as required inputs.  \n",
    "\n",
    "Important methods:\n",
    "- __Connection_to_enpoint:__ Using the request module to approach the twitter api.\n",
    "- __Connection_to_enpoint_loop:__ Connect to endpoint but try a new bearer token if rate limit is reached.\n",
    "- __Snowball:__ Given a twitter user (screenname) as seed retrieve a network of users. Output is a pandas dataframe.\n",
    "\n",
    "The data collection is done entirely in the script but is easily importable using `from TwitterNetworkCollectionScript import TwitterAPI`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulisation of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### READ DATA ###\n",
    "\n",
    "df = pd.read_pickle('data/results15062021')\n",
    "\n",
    "#### FORMAT DATA ###\n",
    "\n",
    "df = pd.concat([df,df['public_metrics'].apply(pd.Series)], axis=1)\n",
    "df_username = df.groupby('username')\n",
    "df_username = df_username['name'].count().sort_values(ascending=False)\n",
    "df = pd.merge(df,df_username,left_on='username',right_index = True, suffixes=('','_count')) \n",
    "df = df.rename(columns = {'name_count':'indegree'})\n",
    "\n",
    "# Make a \"wind\" dummy \n",
    "\n",
    "df.loc[(df['description'].str.contains('(?i)Wind(?!ow)')) | \n",
    "            (df['username'].str.contains('(?i)Wind(?!ow)')), 'wind'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gps_of_location(location, header = ''):\n",
    "    google_API_key = AppCred.GOOGLE_API_KEY\n",
    "    url = f\"https://maps.googleapis.com/maps/api/geocode/json?address={location}&key={google_API_key}\"\n",
    "    api = TwitterAPI(header)\n",
    "    try: \n",
    "        json_response = api.connect_to_endpoint(url=url)\n",
    "    except:\n",
    "        return 'No GPS coordinates found'\n",
    "    if json_response['status'] == 'OK':\n",
    "        d = json_response['results'][0]['geometry']['location']\n",
    "        d['types_google_api_response'] = json_response['results'][0]['types']\n",
    "        return d\n",
    "    elif json_response['status'] == 'REQUEST_DENIED':\n",
    "        return json_response\n",
    "    else:\n",
    "        return 'No GPS coordinates found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect gps coordinates from locations\n",
    "\n",
    "from TwitterNetworkCollectionScript import TwitterAPI\n",
    "\n",
    "#Use the twitter api collect to endpoint function - not a clean way to do it - but fun\n",
    "api = TwitterAPI('')\n",
    "\n",
    "#remove special characters in location\n",
    "df['location_trimmed'] = df['location']\n",
    "locations = df_results.loc[df['wind'] == 1, 'location_trimmed'].apply(lambda x : re.sub('/[!@#$%^&*]/g', ' ', str(x)))\n",
    "locations = locations.unique()\n",
    "\n",
    "#get gps coordinates from the twitter users' own location description\n",
    "gps = {x : gps_of_location(x) for x in locations}\n",
    "#map to dataframe\n",
    "df_gps = pd.DataFrame(gps).transpose()\n",
    "#merge with original dataframe\n",
    "df = pd.merge(df,df_gps, left_on = 'location', right_index = True, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#construct map\n",
    "\n",
    "#filter out response types that indicates the users location description is not really a location\n",
    "filter_list = ['political','natural_feature']\n",
    "df['geo_type_filter'] = df['types_google_api_response'] \n",
    "df['geo_type_filter'] = df['geo_type_filter'].apply(lambda x : any(y in x for y in filter_list) \n",
    "                                                                    if isinstance(x,list) else False)\n",
    "df_map = df.loc[(df['wind'] == 1)&(df['geo_type_filter']==True)].drop_duplicates('username')\n",
    "\n",
    "#rename columns for legend to be pretty\n",
    "df_map['user_degree'] = df_map['ball_depth'].astype(int)\n",
    "df_map['user_degree'] = df_map['user_degree'].apply(lambda x:str(x+1))\n",
    "\n",
    "#construct the actual map\n",
    "fig = px.scatter_geo(df_map,lat='lat', lon='lng',color='user_degree',hover_name='username')\n",
    "\n",
    "#output\n",
    "fig.write_image('map/static_twitter_user_map.jpeg')\n",
    "fig.write_html(\"map/interactive_twitter_user_map.html\")\n",
    "fig.show()"
   ]
  },
  {
   "source": [
    "### Create a network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_seeds = len(df_results['followed_by'].unique())\n",
    "number_of_nodes = len(df_results['username'].unique())\n",
    "df_results_no_duplicates = df_results.drop_duplicates(['followed_by','username'])\n",
    "number_of_edges = len(df_results_no_duplicates)\n",
    "print(f'''__Network statistics__\n",
    "Number of seeds used: {number_of_seeds}\n",
    "Number of nodes: {number_of_nodes}\n",
    "Number of edges in network: {number_of_edges}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_network = df_results.copy()\n",
    "#Filter out non-wind\n",
    "df_network = df_network.loc[df_network['wind']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create graph object\n",
    "G = nx.from_pandas_edgelist(df_network ,source = 'followed_by', target = 'username', edge_attr = ['username','followed_by', 'ball_depth'] ,create_using = nx.DiGraph())\n",
    "#create node attributes\n",
    "nodes = df_network.drop_duplicates('username')\n",
    "nodes = nodes.rename(columns={'username' : 'node'})\n",
    "node_attributes = nodes.set_index('node').to_dict('index')\n",
    "nx.set_node_attributes(G,node_attributes)\n",
    "#write to gephi\n",
    "nx.write_gexf(G, 'Graphs/WindWatchOrg_snowball_sample_v3_only_wind.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd03ed8ad36289d305c36e0f62c4336657b59989454aba0ee7799c35f3bccb4e530",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
